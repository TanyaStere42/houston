version: "3.8"

services:

  db:
    image: postgres:13.4
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
    user: postgres
    volumes:
      - db-pgdata-var:/var/lib/postgresql/data
      # DB initialization scripts
      - .dockerfiles/db/initdb.d/:/docker-entrypoint-initdb.d/
    networks:
      - intranet
    environment:
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      WBIA_DB_NAME: "${WBIA_DB_NAME}"
      WBIA_DB_USER: "${WBIA_DB_USER}"
      WBIA_DB_PASSWORD: "${WBIA_DB_PASSWORD}"
      WILDBOOK_DB_NAME: "${WILDBOOK_DB_NAME}"
      WILDBOOK_DB_USER: "${WILDBOOK_DB_USER}"
      WILDBOOK_DB_PASSWORD: "${WILDBOOK_DB_PASSWORD}"
      HOUSTON_DB_NAME: "${HOUSTON_DB_NAME}"
      HOUSTON_DB_USER: "${HOUSTON_DB_USER}"
      HOUSTON_DB_PASSWORD: "${HOUSTON_DB_PASSWORD}"

  redis:
    image: redis:latest
    command: ["redis-server", "/redis.conf"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes:
      - redis-var:/data
      - .dockerfiles/redis/redis.conf:/redis.conf
    networks:
      - intranet

  elasticsearch:
    # https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes:
      - es-var1:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - intranet
    ports:
      # development exposure, not exposed in production
      - 9200:9200
      - 9300:9300
    environment:
      - node.name=elasticsearch
      - discovery.seed_hosts=elasticsearch2,elasticsearch3
      - cluster.initial_master_nodes=elasticsearch,elasticsearch2,elasticsearch3
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

  elasticsearch2:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes:
      - es-var2:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - intranet
    environment:
      - node.name=elasticsearch2
      - discovery.seed_hosts=elasticsearch,elasticsearch3
      - cluster.initial_master_nodes=elasticsearch,elasticsearch2,elasticsearch3
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

  elasticsearch3:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    depends_on:
      - elasticsearch2
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes:
      - es-var3:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - intranet
    environment:
      - node.name=elasticsearch3
      - discovery.seed_hosts=elasticsearch,elasticsearch2
      - cluster.initial_master_nodes=elasticsearch,elasticsearch2,elasticsearch3
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.0
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:5601/status || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
    networks:
      - intranet
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_HOSTS: "http://${ELASTICSEARCH_HOSTS}"

  acm:
    # https://github.com/WildMeOrg/wildbook-ia
    image: wildme/wbia:latest
    command: ["--db-uri", "${WBIA_DB_URI}"]
    depends_on:
      db:
        condition: service_healthy
    # healthcheck:  # WBIA defines it's own health check
    volumes:
      - acm-database-var:/data/db
      - acm-cache-var:/cache
    networks:
      - intranet
    ports:
      # FIXME: exposed for developer verification
      - "82:5000"
    environment:
      WBIA_DB_URI: "${WBIA_DB_URI}"
      HOUSTON_CLIENT_ID: "${HOUSTON_CLIENT_ID}"
      HOUSTON_CLIENT_SECRET: "${HOUSTON_CLIENT_SECRET}"

  houston:
    # https://github.com/WildMeOrg/houston
    image: wildme/houston:latest
    build: &houston-build
      context: .
      target: main
    command: ["invoke", "app.run"]
    depends_on:
      db:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5000/api/v1/site-settings/heartbeat"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes: &houston-volumes
      - houston-var:/data
      # These are added for development. Do not mount these in production.
      - .dockerfiles/docker-entrypoint.sh:/docker-entrypoint.sh
      - .dockerfiles/docker-entrypoint-init.d.mws:/docker-entrypoint-init.d
      - .dockerfiles/docker-entrypoint-always-init.d:/docker-entrypoint-always-init.d
      # FIXME: pull in development code while working on bringing up the container
      - .:/code
    networks:
      - intranet
      - frontend
    ports:
      # FIXME: exposed for developer verification
      - "83:5000"
    environment: &houston-environment
      HOUSTON_APP_CONTEXT: mws
      FLASK_ENV: development
      SQLALCHEMY_DATABASE_URI: "${SQLALCHEMY_DATABASE_URI}"
      TEST_DATABASE_URI: "${TEST_DATABASE_URI}"
      ACM_AUTHENTICATIONS_URI__DEFAULT: "${ACM_AUTHENTICATIONS_URI__DEFAULT}"
      ELASTICSEARCH_HOSTS: "${ELASTICSEARCH_HOSTS}"
      HOUSTON_URL: "${HOUSTON_URL}"
      REDIS_HOST: redis
      REDIS_PASSWORD: "seekret_development_password"
      GITLAB_PROTO: "${GITLAB_PROTO}"
      GITLAB_HOST: "${GITLAB_HOST}"
      GITLAB_PORT: "${GITLAB_PORT}"
      GITLAB_ADMIN_PASSWORD: "${GITLAB_ADMIN_PASSWORD}"
      GITLAB_REMOTE_URI: "${GITLAB_REMOTE_URI}"
      GITLAB_REMOTE_LOGIN_PAT: "${GITLAB_REMOTE_LOGIN_PAT}"
      GITLAB_NAMESPACE: "${GITLAB_NAMESPACE}"
      GIT_SSH_KEY: "${GIT_SSH_KEY}"
      GIT_PUBLIC_NAME: "${GIT_PUBLIC_NAME}"
      GIT_EMAIL: "${GIT_EMAIL}"
      OAUTH_CLIENT_ID: "${HOUSTON_CLIENT_ID}"
      OAUTH_CLIENT_SECRET: "${HOUSTON_CLIENT_SECRET}"
      OAUTH_USER_EMAIL: "${OAUTH_USER_EMAIL}"
      WILDBOOK_DB_HOST: "${WILDBOOK_DB_HOST}"
      WILDBOOK_DB_NAME: "${WILDBOOK_DB_NAME}"
      WILDBOOK_DB_USER: "${WILDBOOK_DB_USER}"
      WILDBOOK_DB_PASSWORD: "${WILDBOOK_DB_PASSWORD}"
      LOG_WIDTH: ${LOG_WIDTH}

  celery_beat:
    image: wildme/houston:latest
    build: *houston-build
    command: ["celery", "-A", "app.extensions.celery.celery", "beat", "-s", "/data/var/celerybeat-schedule", "-l", "INFO"]
    depends_on:
      houston:
        condition: service_healthy
    healthcheck: &celery-healthcheck
      test: [ "CMD", "celery", "-A", "app.extensions.celery.celery", "status", "--timeout", "2"]
      interval: 10s
      timeout: 8s
      retries: 60
    volumes: *houston-volumes
    networks:
      - intranet
    environment: *houston-environment

  celery_worker:
    image: wildme/houston:latest
    build: *houston-build
    command: ["celery", "-A", "app.extensions.celery.celery", "worker", "-l", "INFO", "--pool=gevent"]
    depends_on:
      houston:
        condition: service_healthy
    healthcheck: *celery-healthcheck
    volumes: *houston-volumes
    networks:
      - intranet
    environment: *houston-environment

  celery_worker_2:
    image: wildme/houston:latest
    build: *houston-build
    command: ["celery", "-A", "app.extensions.celery.celery", "worker", "-l", "INFO", "--pool=gevent"]
    depends_on:
      houston:
        condition: service_healthy
    healthcheck: *celery-healthcheck
    volumes: *houston-volumes
    networks:
      - intranet
    environment: *houston-environment

  celery_worker_3:
    image: wildme/houston:latest
    build: *houston-build
    command: ["celery", "-A", "app.extensions.celery.celery", "worker", "-l", "INFO", "--pool=gevent"]
    depends_on:
      houston:
        condition: service_healthy
    healthcheck: *celery-healthcheck
    volumes: *houston-volumes
    networks:
      - intranet
    environment: *houston-environment

  flower:
    image: wildme/houston:latest
    build: *houston-build
    command: ["celery", "-A", "app.extensions.celery.celery", "flower", "--basic_auth=${FLOWER_USER}:${FLOWER_PASSWORD}"]
    depends_on:
      houston:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://${FLOWER_USER}:${FLOWER_PASSWORD}@localhost:5555/metrics"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes: *houston-volumes
    networks:
      - intranet
    environment: *houston-environment
    ports:
      - "86:5555"

  dev-frontend:
    # this component is intended to only be used in development
    image: node:lts
    working_dir: /code
    entrypoint: "/docker-entrypoint.sh"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes:
      - .dockerfiles/dev-frontend/docker-entrypoint.sh:/docker-entrypoint.sh
      - ./:/code
    networks:
      - intranet
    environment:
      HOUSTON_APP_CONTEXT: mws
      # See port served by 'www' component (i.e. the reverse proxy)
      HOST: "0.0.0.0"
      PORT: "84"

  www:
    image: nginx:latest
    depends_on:
      # acm:
      #   condition: service_healthy
      houston:
        condition: service_healthy
      dev-frontend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:80/"]
      interval: 10s
      timeout: 5s
      retries: 60
    volumes:
      - .dockerfiles/www/nginx.conf:/etc/nginx/conf.d/default.conf
    networks:
      - intranet
      - frontend
    ports:
      - "84:80"

networks:
  intranet:
  frontend:

volumes:
  db-pgdata-var:
  es-var1:
  es-var2:
  es-var3:
  redis-var:
  acm-database-var:
  acm-cache-var:
  houston-var:
